PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_single_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_single_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_single_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_multivalue --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task niah_multiquery --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task vt --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task cwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task fwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task qa_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/131072/data --benchmark synthetic --task qa_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 131072 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_single_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_single_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_single_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_multivalue --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task niah_multiquery --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task vt --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task cwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task fwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task qa_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/65536/data --benchmark synthetic --task qa_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 65536 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_single_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_single_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_single_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_multivalue --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task niah_multiquery --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task vt --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task cwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task fwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task qa_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/32768/data --benchmark synthetic --task qa_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 32768 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_single_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_single_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_single_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_multivalue --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task niah_multiquery --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task vt --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task cwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task fwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task qa_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/16384/data --benchmark synthetic --task qa_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 16384 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_single_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_single_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_single_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_multivalue --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task niah_multiquery --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task vt --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task cwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task fwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task qa_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/8192/data --benchmark synthetic --task qa_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 8192 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_single_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_single_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_single_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_multivalue --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task niah_multiquery --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task vt --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task cwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task fwe --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task qa_1 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/llama3.1-8b/synthetic/4096/data --benchmark synthetic --task qa_2 --tokenizer_path meta-llama/Llama-3.1-8B --tokenizer_type hf --max_seq_length 4096 --model_template_type meta-llama-noinstruct --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_single_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_single_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_single_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_multivalue --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task niah_multiquery --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task vt --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task cwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task fwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task qa_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/131072/data --benchmark synthetic --task qa_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 131072 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_single_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_single_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_single_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_multivalue --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task niah_multiquery --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task vt --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task cwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task fwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task qa_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/65536/data --benchmark synthetic --task qa_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 65536 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_single_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_single_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_single_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_multivalue --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task niah_multiquery --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task vt --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task cwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task fwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task qa_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/32768/data --benchmark synthetic --task qa_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 32768 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_single_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_single_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_single_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_multivalue --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task niah_multiquery --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task vt --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task cwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task fwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task qa_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/16384/data --benchmark synthetic --task qa_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 16384 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_single_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_single_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_single_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_multivalue --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task niah_multiquery --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task vt --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task cwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task fwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task qa_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/8192/data --benchmark synthetic --task qa_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 8192 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_single_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_single_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_single_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_multikey_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_multikey_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_multikey_3 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_multivalue --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task niah_multiquery --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task vt --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task cwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task fwe --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task qa_1 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python data/prepare.py --save_dir benchmark_root/xLSTM-7b-longctx/synthetic/4096/data --benchmark synthetic --task qa_2 --tokenizer_path xlstm --tokenizer_type hf --max_seq_length 4096 --model_template_type 16 --num_samples 500
